Project write-up available in the README file.

Extract: Data Sources and Formats

World Happiness 2018 (CSV) : https://www.kaggle.com/njlow1202/world-happiness-report-data-2018
World Happiness 2017 (CSV) : https://www.kaggle.com/unsdsn/world-happiness#2017.csv
Transform: Data Cleaning/Transformation Required

We started by creating a filtered dataframe from specific columns of the first data source (country, happiness rank, happiness score, health life expectancy, freedom, generosity, gdp, government corruption) to bring in only the columns that we would want to use in the analysis. Next we cleaned up the column headers by renaming several of the columns. From the second data source we repeated the first two steps -creating a filtered dataframe from specific columns and renaming the headers to coordinate (when needed) with the first data set.

Load: Final Database, Tables/Collections, Why This Was Chosen

The final database used for this analysis is SQLpostgres. In[6] of the jupyter notebook creates a database connection allowing us to work with our cleaned data in a relational database. The benefits of using SQL are that relational databased enable dynamic views and allow for us to explore the two data sets while maintaining a defined relationship between the two. Since our two data sources represent YoY change in world happiness statistics, having that set relationship with flexibility in view depending on needs of specific analysis is crucial.
